{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attempt to run the author's model with a 66/33 train/test split \n",
    "# and 25-fold cross validation on the 66% to evaluate performance\n",
    "# then predict the final 33% for comparison\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Load the data\n",
    "main_data = pd.read_csv(\"./data/train.csv\")\n",
    "\n",
    "# 'critical_temp' is the target\n",
    "X = main_data.drop('critical_temp', axis=1)\n",
    "y = main_data['critical_temp']\n",
    "\n",
    "# Split the data into training and testing sets (66/33 split)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "# Create a baseline XGBoost model with the parameters specified in the paper\n",
    "xgb_model = XGBRegressor(\n",
    "    n_estimators=374,         # Tree size: 374\n",
    "    max_depth=16,             # Maximum depth: 16\n",
    "    learning_rate=0.02,       # Learning rate (η): 0.02\n",
    "    min_child_weight=1,       # Minimum child weight: 1\n",
    "    colsample_bytree=0.5,     # Column subsampling: 0.50\n",
    "    random_state=42,\n",
    "    objective='reg:squarederror'\n",
    ")\n",
    "\n",
    "# Define scoring metrics: note that RMSE is returned as a negative value.\n",
    "scoring = {\n",
    "    \"rmse\": \"neg_root_mean_squared_error\",\n",
    "    \"r2\": \"r2\"\n",
    "}\n",
    "\n",
    "# Perform 25-fold cross-validation using cross_validate only on the train data\n",
    "cv_results = cross_validate(xgb_model, X_train, y_train, cv=25, scoring=scoring)\n",
    "\n",
    "# Extract and convert RMSE scores to positive values\n",
    "rmse_scores = -cv_results[\"test_rmse\"]\n",
    "r2_scores = cv_results[\"test_r2\"]\n",
    "\n",
    "# Print RMSE and R² for each fold\n",
    "for i, (rmse, r2) in enumerate(zip(rmse_scores, r2_scores), start=1):\n",
    "    print(f\"Fold {i}: RMSE = {rmse:.4f}, R² = {r2:.4f}\")\n",
    "\n",
    "# Calculate and print the overall average scores\n",
    "avg_rmse = np.mean(rmse_scores)\n",
    "avg_r2 = np.mean(r2_scores)\n",
    "print(f\"\\nAverage Cross-validated RMSE (25 folds): {avg_rmse:.4f}\")\n",
    "print(f\"\\nAverage Cross-validated R² (25 folds): {avg_r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results:\n",
    "\n",
    "The author's parameters 25-fold corss validation on 66% before using test data to evalute:\n",
    "\n",
    "Fold 1: RMSE = 10.4193, R² = 0.9125\n",
    "Fold 2: RMSE = 9.3529, R² = 0.9293\n",
    "Fold 3: RMSE = 7.5943, R² = 0.9506\n",
    "Fold 4: RMSE = 10.7370, R² = 0.9001\n",
    "Fold 5: RMSE = 9.3011, R² = 0.9222\n",
    "Fold 6: RMSE = 10.4272, R² = 0.9043\n",
    "Fold 7: RMSE = 9.6513, R² = 0.9194\n",
    "Fold 8: RMSE = 10.4734, R² = 0.9035\n",
    "Fold 9: RMSE = 8.4812, R² = 0.9316\n",
    "Fold 10: RMSE = 8.3877, R² = 0.9385\n",
    "Fold 11: RMSE = 8.9062, R² = 0.9254\n",
    "Fold 12: RMSE = 9.0328, R² = 0.9232\n",
    "Fold 13: RMSE = 9.6993, R² = 0.9277\n",
    "Fold 14: RMSE = 10.5692, R² = 0.9067\n",
    "Fold 15: RMSE = 9.3323, R² = 0.9304\n",
    "Fold 16: RMSE = 11.2379, R² = 0.8952\n",
    "Fold 17: RMSE = 9.1582, R² = 0.9295\n",
    "Fold 18: RMSE = 9.7220, R² = 0.9239\n",
    "Fold 19: RMSE = 9.9490, R² = 0.9164\n",
    "Fold 20: RMSE = 9.3758, R² = 0.9250\n",
    "Fold 21: RMSE = 10.2647, R² = 0.9039\n",
    "Fold 22: RMSE = 9.0041, R² = 0.9326\n",
    "Fold 23: RMSE = 7.8902, R² = 0.9519\n",
    "Fold 24: RMSE = 8.8469, R² = 0.9356\n",
    "Fold 25: RMSE = 9.3879, R² = 0.9251\n",
    "\n",
    "Average Cross-validated RMSE (25 folds): 9.4881\n",
    "\n",
    "Average Cross-validated R² (25 folds): 0.9226\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain the model on the full training set (66% of the data)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the reserved test set\n",
    "y_test_pred = xgb_model.predict(X_test)\n",
    "\n",
    "# Evaluate on the test set\n",
    "test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "test_r2 = r2_score(y_test, y_test_pred)\n",
    "\n",
    "print(f\"Reserved Test Set Performance:\")\n",
    "print(f\"Test RMSE: {test_rmse:.4f}\")\n",
    "print(f\"Test R²: {test_r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results:\n",
    "\n",
    "The model evaluated on the reserved 33% test data:\n",
    "\n",
    "Reserved Test Set Performance:\n",
    "Test RMSE: 9.4656\n",
    "Test R²: 0.9230\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
